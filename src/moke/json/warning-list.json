{
  "RECORDS": [
    {
      "id": "3df38325-eedc-4282-9f0e-a40f0e0d0854",
      "type": "4001",
      "content": "",
      "isPredicted": false,
      "createTime": 1705653271936,
      "grade": "A",
      "bindId": "GA61511",
      "bindType": "AIoT",
      "abnormalProbability": 58.40103400093268,
      "process": 2,
      "typeEnum": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      },
      "info": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      }
    },
    {
      "id": "361c31e9-77a3-4a99-9c9a-71c83f88de04",
      "type": "4001",
      "content": "",
      "isPredicted": true,
      "createTime": 1705653271936,
      "grade": "A",
      "bindId": "GA61512",
      "bindType": "AIoT",
      "abnormalProbability": 97.09899949678515,
      "process": 2,
      "typeEnum": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      },
      "info": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      }
    },
    {
      "id": "659c6cd6-c42f-4c98-81b3-6441bcc6a861",
      "type": "4002",
      "content": "",
      "isPredicted": true,
      "createTime": 1705653271936,
      "grade": "B",
      "bindId": "GA61513",
      "bindType": "AIoT",
      "abnormalProbability": 79.55552129374936,
      "process": 1,
      "typeEnum": {
        "name": "AIoT-0x7200/-29184/MBEDTLS_ERR_SSL_INVALID_RECORD",
        "content": "收到非法数据：An invalid SSL record was received",
        "solution": "TCP/IP协议栈收到的数据包出错, 需要排查协议栈方面问题\nSSL所运行的线程栈被设置的过小, 需调整线程栈大小\nSSL被配置的最大报文长度太小, 当网络报文长度超过该数值时, 则可能出现0x7200错误\n可调整 MBEDTLS_SSL_MAX_CONTENT_LEN 的值, 重新编译再试\nMBEDTLS_SSL_MAX_CONTENT_LEN 的值, 目前已知最小不能小于 4096"
      },
      "info": {
        "name": "AIoT-0x7200/-29184/MBEDTLS_ERR_SSL_INVALID_RECORD",
        "content": "收到非法数据：An invalid SSL record was received",
        "solution": "TCP/IP协议栈收到的数据包出错, 需要排查协议栈方面问题\nSSL所运行的线程栈被设置的过小, 需调整线程栈大小\nSSL被配置的最大报文长度太小, 当网络报文长度超过该数值时, 则可能出现0x7200错误\n可调整 MBEDTLS_SSL_MAX_CONTENT_LEN 的值, 重新编译再试\nMBEDTLS_SSL_MAX_CONTENT_LEN 的值, 目前已知最小不能小于 4096"
      }
    },
    {
      "id": "7c9f7cc2-b97e-4bc3-a226-db5fcf327b83",
      "type": "4001",
      "content": "",
      "isPredicted": true,
      "createTime": 1705653271936,
      "grade": "B",
      "bindId": "GA61514",
      "bindType": "AIoT",
      "abnormalProbability": 45.61929598592502,
      "process": 0,
      "typeEnum": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      },
      "info": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      }
    },
    {
      "id": "7a57b586-e0a5-4997-bbc5-2552f5d1f9d4",
      "type": "4002",
      "content": "",
      "isPredicted": false,
      "createTime": 1705653271936,
      "grade": "C",
      "bindId": "GA61510011",
      "bindType": "AIoT",
      "abnormalProbability": 44.45932334820326,
      "process": 0,
      "typeEnum": {
        "name": "AIoT-0x7200/-29184/MBEDTLS_ERR_SSL_INVALID_RECORD",
        "content": "收到非法数据：An invalid SSL record was received",
        "solution": "TCP/IP协议栈收到的数据包出错, 需要排查协议栈方面问题\nSSL所运行的线程栈被设置的过小, 需调整线程栈大小\nSSL被配置的最大报文长度太小, 当网络报文长度超过该数值时, 则可能出现0x7200错误\n可调整 MBEDTLS_SSL_MAX_CONTENT_LEN 的值, 重新编译再试\nMBEDTLS_SSL_MAX_CONTENT_LEN 的值, 目前已知最小不能小于 4096"
      },
      "info": {
        "name": "AIoT-0x7200/-29184/MBEDTLS_ERR_SSL_INVALID_RECORD",
        "content": "收到非法数据：An invalid SSL record was received",
        "solution": "TCP/IP协议栈收到的数据包出错, 需要排查协议栈方面问题\nSSL所运行的线程栈被设置的过小, 需调整线程栈大小\nSSL被配置的最大报文长度太小, 当网络报文长度超过该数值时, 则可能出现0x7200错误\n可调整 MBEDTLS_SSL_MAX_CONTENT_LEN 的值, 重新编译再试\nMBEDTLS_SSL_MAX_CONTENT_LEN 的值, 目前已知最小不能小于 4096"
      }
    },
    {
      "id": "b931195d-470a-49b6-a614-a3437cb05fc1",
      "type": "4001",
      "content": "",
      "isPredicted": false,
      "createTime": 1705653271936,
      "grade": "C",
      "bindId": "GA61510031",
      "bindType": "AIoT",
      "abnormalProbability": 81.27895536325592,
      "process": 0,
      "typeEnum": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      },
      "info": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      }
    },
    {
      "id": "4fa8fc8e-2d67-404a-9d10-22cbdbec3e69",
      "type": "4001",
      "content": "",
      "isPredicted": false,
      "createTime": 1705653271936,
      "grade": "C",
      "bindId": "GA61510032",
      "bindType": "AIoT",
      "abnormalProbability": 54.61904170901357,
      "process": 2,
      "typeEnum": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      },
      "info": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      }
    },
    {
      "id": "fd710a31-e8ee-4a02-8598-f2d51dc71d62",
      "type": "4001",
      "content": "",
      "isPredicted": true,
      "createTime": 1705653271936,
      "grade": "C",
      "bindId": "GA61510033",
      "bindType": "AIoT",
      "abnormalProbability": 13.663408737861005,
      "process": 1,
      "typeEnum": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      },
      "info": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      }
    },
    {
      "id": "6c8a1811-a15a-416a-9d39-ab303cdffc59",
      "type": "4001",
      "content": "",
      "isPredicted": true,
      "createTime": 1705653271936,
      "grade": "C",
      "bindId": "GA61510041",
      "bindType": "AIoT",
      "abnormalProbability": 10.80372452558047,
      "process": 2,
      "typeEnum": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      },
      "info": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      }
    },
    {
      "id": "81dac4f6-ad9a-4efb-8a9f-f4064fbfee63",
      "type": "4001",
      "content": "",
      "isPredicted": true,
      "createTime": 1705653271936,
      "grade": "C",
      "bindId": "GA61510042",
      "bindType": "AIoT",
      "abnormalProbability": 26.553838842311727,
      "process": 0,
      "typeEnum": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      },
      "info": {
        "name": "AIoT-0x7880/-30848/MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY",
        "content": "云端把SSL连接断开了：The peer notified us that the connection is going to be closed",
        "solution": "设备端数据连接过于频繁, 触发云端限流, 断开设备\n建议关闭设备, 等待一段时间（5分钟以后）再发起连接重试，观察错误仍会出现\n有多个设备使用相同的productKey和deviceName与云端建立连接，导致被云端踢下线\n建议检查当前使用的设备证书（ProductKey、DeviceName、DeviceSecret）是否可能被他人使用\n设备端保活出错, 没有及时发送 MQTT ping packet，或者被发送了没有及时到达云端\n建议用抓包等方式确认心跳包有成功发出或者观察有没有收到来自服务端的 MQTT ping response\n如果一次都不能连接成功，可以考虑是不是大小端字节序不匹配\n目前C-SDK 默认是适配小端设备, 如果需在大端硬件上工作，请添加全局编译选项 REVERSED"
      }
    },
    {
      "id": "be314038-a269-42d8-ba07-3ecf7bc47720",
      "type": "1001",
      "content": "",
      "isPredicted": false,
      "createTime": 1705666972529,
      "grade": "C",
      "bindId": "1",
      "bindType": "master",
      "abnormalProbability": 49.36974273820507,
      "process": 2,
      "typeEnum": {
        "name": "Spark-IO错误",
        "content": "\n    java.io.IOException: Failed to delete: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-0395885c-99ff-427e-885a-34d036a28999\n\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:928)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:174)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:170)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n\tat org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:170)\n\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:162)\n\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1233)\n\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:96)\n\tat org.apache.spark.executor.Executor.stop(Executor.scala:143)\n\tat org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:115)\n\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:116)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:204)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:215)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "\n    确认文件或目录是否存在： 确保指定的路径下的文件或目录确实存在。\n\n检查权限： 确保执行删除操作的用户具有足够的权限，包括对父目录的写权限。\n\n检查文件是否被占用： 确保没有其他进程正在使用该文件或目录。您可以使用操作系统的工具来查看文件的占用情况。\n\n检查文件系统状态： 检查文件系统是否正常，没有只读等问题。\n\n验证路径的正确性： 确保指定的路径中的所有目录都存在，没有拼写错误或其他问题。\n    "
      },
      "info": {
        "name": "Spark-IO错误",
        "content": "\n    java.io.IOException: Failed to delete: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-0395885c-99ff-427e-885a-34d036a28999\n\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:928)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:174)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:170)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n\tat org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:170)\n\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:162)\n\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1233)\n\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:96)\n\tat org.apache.spark.executor.Executor.stop(Executor.scala:143)\n\tat org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:115)\n\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:116)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:204)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:215)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "\n    确认文件或目录是否存在： 确保指定的路径下的文件或目录确实存在。\n\n检查权限： 确保执行删除操作的用户具有足够的权限，包括对父目录的写权限。\n\n检查文件是否被占用： 确保没有其他进程正在使用该文件或目录。您可以使用操作系统的工具来查看文件的占用情况。\n\n检查文件系统状态： 检查文件系统是否正常，没有只读等问题。\n\n验证路径的正确性： 确保指定的路径中的所有目录都存在，没有拼写错误或其他问题。\n    "
      }
    },
    {
      "id": "55cda213-ef72-4c84-894c-9bd22c929353",
      "type": "1002",
      "content": "",
      "isPredicted": true,
      "createTime": 1705666972529,
      "grade": "C",
      "bindId": "1001",
      "bindType": "worker",
      "abnormalProbability": 14.925284584837772,
      "process": 0,
      "typeEnum": {
        "name": "Spark-Task Exception",
        "content": "\n    16/04/07 10:46:31 WARN executor.CoarseGrainedExecutorBackend: An unknown (mesos-slave-24:43670) driver disconnected.\n16/04/07 10:46:31 ERROR executor.CoarseGrainedExecutorBackend: Driver 10.10.34.34:43670 disassociated! Shutting down.\n16/04/07 10:46:31 ERROR executor.Executor: Exception in task 8.0 in stage 0.0 (TID 11)\njava.io.IOException: Failed to create local dir in /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-bcb1cfe2-beb8-4f46-b500-2a6945695a47/04.\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:73)\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:83)\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:53)\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.writeIndexFileAndCommit(IndexShuffleBlockResolver.scala:154)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:128)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "根据错误信息，查询Spark任务失败，查看失败原因。"
      },
      "info": {
        "name": "Spark-Task Exception",
        "content": "\n    16/04/07 10:46:31 WARN executor.CoarseGrainedExecutorBackend: An unknown (mesos-slave-24:43670) driver disconnected.\n16/04/07 10:46:31 ERROR executor.CoarseGrainedExecutorBackend: Driver 10.10.34.34:43670 disassociated! Shutting down.\n16/04/07 10:46:31 ERROR executor.Executor: Exception in task 8.0 in stage 0.0 (TID 11)\njava.io.IOException: Failed to create local dir in /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-bcb1cfe2-beb8-4f46-b500-2a6945695a47/04.\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:73)\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:83)\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:53)\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.writeIndexFileAndCommit(IndexShuffleBlockResolver.scala:154)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:128)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "根据错误信息，查询Spark任务失败，查看失败原因。"
      }
    },
    {
      "id": "5d983ac0-4d91-4418-9e65-7d7900366c93",
      "type": "1001",
      "content": "",
      "isPredicted": true,
      "createTime": 1705666972529,
      "grade": "C",
      "bindId": "1002",
      "bindType": "worker",
      "abnormalProbability": 99.27445824382252,
      "process": 1,
      "typeEnum": {
        "name": "Spark-IO错误",
        "content": "\n    java.io.IOException: Failed to delete: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-0395885c-99ff-427e-885a-34d036a28999\n\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:928)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:174)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:170)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n\tat org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:170)\n\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:162)\n\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1233)\n\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:96)\n\tat org.apache.spark.executor.Executor.stop(Executor.scala:143)\n\tat org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:115)\n\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:116)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:204)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:215)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "\n    确认文件或目录是否存在： 确保指定的路径下的文件或目录确实存在。\n\n检查权限： 确保执行删除操作的用户具有足够的权限，包括对父目录的写权限。\n\n检查文件是否被占用： 确保没有其他进程正在使用该文件或目录。您可以使用操作系统的工具来查看文件的占用情况。\n\n检查文件系统状态： 检查文件系统是否正常，没有只读等问题。\n\n验证路径的正确性： 确保指定的路径中的所有目录都存在，没有拼写错误或其他问题。\n    "
      },
      "info": {
        "name": "Spark-IO错误",
        "content": "\n    java.io.IOException: Failed to delete: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-0395885c-99ff-427e-885a-34d036a28999\n\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:928)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:174)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:170)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n\tat org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:170)\n\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:162)\n\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1233)\n\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:96)\n\tat org.apache.spark.executor.Executor.stop(Executor.scala:143)\n\tat org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:115)\n\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:116)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:204)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:215)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "\n    确认文件或目录是否存在： 确保指定的路径下的文件或目录确实存在。\n\n检查权限： 确保执行删除操作的用户具有足够的权限，包括对父目录的写权限。\n\n检查文件是否被占用： 确保没有其他进程正在使用该文件或目录。您可以使用操作系统的工具来查看文件的占用情况。\n\n检查文件系统状态： 检查文件系统是否正常，没有只读等问题。\n\n验证路径的正确性： 确保指定的路径中的所有目录都存在，没有拼写错误或其他问题。\n    "
      }
    },
    {
      "id": "77bb6ba8-838d-4ab2-8ca7-b42a453c321b",
      "type": "1001",
      "content": "",
      "isPredicted": false,
      "createTime": 1705666972529,
      "grade": "C",
      "bindId": "1003",
      "bindType": "worker",
      "abnormalProbability": 13.034279165035034,
      "process": 0,
      "typeEnum": {
        "name": "Spark-IO错误",
        "content": "\n    java.io.IOException: Failed to delete: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-0395885c-99ff-427e-885a-34d036a28999\n\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:928)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:174)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:170)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n\tat org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:170)\n\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:162)\n\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1233)\n\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:96)\n\tat org.apache.spark.executor.Executor.stop(Executor.scala:143)\n\tat org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:115)\n\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:116)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:204)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:215)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "\n    确认文件或目录是否存在： 确保指定的路径下的文件或目录确实存在。\n\n检查权限： 确保执行删除操作的用户具有足够的权限，包括对父目录的写权限。\n\n检查文件是否被占用： 确保没有其他进程正在使用该文件或目录。您可以使用操作系统的工具来查看文件的占用情况。\n\n检查文件系统状态： 检查文件系统是否正常，没有只读等问题。\n\n验证路径的正确性： 确保指定的路径中的所有目录都存在，没有拼写错误或其他问题。\n    "
      },
      "info": {
        "name": "Spark-IO错误",
        "content": "\n    java.io.IOException: Failed to delete: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-0395885c-99ff-427e-885a-34d036a28999\n\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:928)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:174)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:170)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n\tat org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:170)\n\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:162)\n\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1233)\n\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:96)\n\tat org.apache.spark.executor.Executor.stop(Executor.scala:143)\n\tat org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:115)\n\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:116)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:204)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:215)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "\n    确认文件或目录是否存在： 确保指定的路径下的文件或目录确实存在。\n\n检查权限： 确保执行删除操作的用户具有足够的权限，包括对父目录的写权限。\n\n检查文件是否被占用： 确保没有其他进程正在使用该文件或目录。您可以使用操作系统的工具来查看文件的占用情况。\n\n检查文件系统状态： 检查文件系统是否正常，没有只读等问题。\n\n验证路径的正确性： 确保指定的路径中的所有目录都存在，没有拼写错误或其他问题。\n    "
      }
    },
    {
      "id": "da489155-2600-4c4d-84d7-052436202d84",
      "type": "1001",
      "content": "",
      "isPredicted": true,
      "createTime": 1705666972529,
      "grade": "C",
      "bindId": "1004",
      "bindType": "worker",
      "abnormalProbability": 15.199981838563259,
      "process": 0,
      "typeEnum": {
        "name": "Spark-IO错误",
        "content": "\n    java.io.IOException: Failed to delete: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-0395885c-99ff-427e-885a-34d036a28999\n\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:928)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:174)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:170)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n\tat org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:170)\n\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:162)\n\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1233)\n\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:96)\n\tat org.apache.spark.executor.Executor.stop(Executor.scala:143)\n\tat org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:115)\n\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:116)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:204)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:215)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "\n    确认文件或目录是否存在： 确保指定的路径下的文件或目录确实存在。\n\n检查权限： 确保执行删除操作的用户具有足够的权限，包括对父目录的写权限。\n\n检查文件是否被占用： 确保没有其他进程正在使用该文件或目录。您可以使用操作系统的工具来查看文件的占用情况。\n\n检查文件系统状态： 检查文件系统是否正常，没有只读等问题。\n\n验证路径的正确性： 确保指定的路径中的所有目录都存在，没有拼写错误或其他问题。\n    "
      },
      "info": {
        "name": "Spark-IO错误",
        "content": "\n    java.io.IOException: Failed to delete: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-0395885c-99ff-427e-885a-34d036a28999\n\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:928)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:174)\n\tat org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:170)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n\tat org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:170)\n\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:162)\n\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1233)\n\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:96)\n\tat org.apache.spark.executor.Executor.stop(Executor.scala:143)\n\tat org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:115)\n\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:116)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:204)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:215)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n    ",
        "solution": "\n    确认文件或目录是否存在： 确保指定的路径下的文件或目录确实存在。\n\n检查权限： 确保执行删除操作的用户具有足够的权限，包括对父目录的写权限。\n\n检查文件是否被占用： 确保没有其他进程正在使用该文件或目录。您可以使用操作系统的工具来查看文件的占用情况。\n\n检查文件系统状态： 检查文件系统是否正常，没有只读等问题。\n\n验证路径的正确性： 确保指定的路径中的所有目录都存在，没有拼写错误或其他问题。\n    "
      }
    }
  ]
}
